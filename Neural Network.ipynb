{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss_with_reg, loss)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.287477, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278345, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.304434, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291038, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279865, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291591, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274757, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296019, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290835, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.309503, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296016, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289155, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287026, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296180, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298523, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283773, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299004, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297151, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301370, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300001, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff7fa5115f8>]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.249676, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.172018, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.393601, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.065546, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.184608, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.328527, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.376202, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.186179, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.152983, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240037, Train accuracy: 0.208556, val accuracy: 0.214000\n",
      "Loss: 2.054349, Train accuracy: 0.231222, val accuracy: 0.234000\n",
      "Loss: 2.211609, Train accuracy: 0.251000, val accuracy: 0.253000\n",
      "Loss: 2.061040, Train accuracy: 0.260556, val accuracy: 0.261000\n",
      "Loss: 1.752975, Train accuracy: 0.273222, val accuracy: 0.270000\n",
      "Loss: 2.011026, Train accuracy: 0.279111, val accuracy: 0.283000\n",
      "Loss: 2.116826, Train accuracy: 0.292889, val accuracy: 0.296000\n",
      "Loss: 1.852094, Train accuracy: 0.314556, val accuracy: 0.320000\n",
      "Loss: 1.899466, Train accuracy: 0.333111, val accuracy: 0.331000\n",
      "Loss: 1.883799, Train accuracy: 0.349222, val accuracy: 0.347000\n",
      "Loss: 1.873020, Train accuracy: 0.377222, val accuracy: 0.372000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.848220, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.839634, Train accuracy: 0.379778, val accuracy: 0.386000\n",
      "Loss: 1.836308, Train accuracy: 0.486667, val accuracy: 0.480000\n",
      "Loss: 1.323253, Train accuracy: 0.539556, val accuracy: 0.540000\n",
      "Loss: 1.685546, Train accuracy: 0.590667, val accuracy: 0.600000\n",
      "Loss: 1.620820, Train accuracy: 0.633000, val accuracy: 0.631000\n",
      "Loss: 1.561064, Train accuracy: 0.641778, val accuracy: 0.633000\n",
      "Loss: 1.625252, Train accuracy: 0.650889, val accuracy: 0.662000\n",
      "Loss: 1.935754, Train accuracy: 0.658667, val accuracy: 0.647000\n",
      "Loss: 1.547062, Train accuracy: 0.678111, val accuracy: 0.675000\n",
      "Loss: 1.202394, Train accuracy: 0.665778, val accuracy: 0.657000\n",
      "Loss: 1.585595, Train accuracy: 0.682778, val accuracy: 0.650000\n",
      "Loss: 1.749854, Train accuracy: 0.696889, val accuracy: 0.687000\n",
      "Loss: 1.544860, Train accuracy: 0.700444, val accuracy: 0.679000\n",
      "Loss: 1.366094, Train accuracy: 0.696667, val accuracy: 0.683000\n",
      "Loss: 1.409810, Train accuracy: 0.686333, val accuracy: 0.664000\n",
      "Loss: 2.075150, Train accuracy: 0.683222, val accuracy: 0.667000\n",
      "Loss: 1.349267, Train accuracy: 0.674667, val accuracy: 0.663000\n",
      "Loss: 1.175001, Train accuracy: 0.704444, val accuracy: 0.673000\n",
      "Loss: 1.648631, Train accuracy: 0.707778, val accuracy: 0.686000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-2, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.330485, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.305156, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.290896, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.218982, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.232592, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.455425, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.357058, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.175870, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.347766, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.530197, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.616004, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.953972, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.821688, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.274173, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.116733, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.528619, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.255940, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.211496, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 2.125309, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.752292, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.532168, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.343800, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Loss: 1.604978, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.449016, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.022294, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.069527, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.793240, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.253043, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.545801, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.162101, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.951166, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.476330, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.390052, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.926812, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.926397, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.522266, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.790132, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.476385, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.418847, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.492228, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.902852, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.694214, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.772398, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.634660, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.873764, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.627933, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.761974, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.664166, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.630728, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.619058, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.646790, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.607321, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.689314, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.532595, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.611692, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.573860, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.586106, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.613858, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.540422, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.570415, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.566029, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.505976, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.514699, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.547491, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.579262, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.667853, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.592241, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.705427, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.567144, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.662589, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.615134, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.528234, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.611808, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.670565, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.575584, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.539156, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.542321, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.587080, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.607238, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.601760, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.562863, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.530874, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.567698, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.572166, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.590667, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.615246, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.558291, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.543506, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.556242, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.625347, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.610677, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.571067, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.566520, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.552887, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.629123, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.572221, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.524623, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.656897, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.556127, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.541019, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.599494, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.545177, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.547771, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.545046, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.563293, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.585778, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.583746, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.589007, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.582095, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.630284, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.495579, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.609229, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.475090, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.573180, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.560663, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.611668, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.641266, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.519767, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.635673, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.553689, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.560410, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.575530, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.586129, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.639372, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.572230, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.588273, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.538285, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.582473, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.675346, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.534969, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.551137, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.582798, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.605411, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.596989, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.581634, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.565011, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.510105, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.575138, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.662006, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.564540, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.567177, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.600995, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.520939, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.595737, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.611112, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.542157, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.550310, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.575734, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.577011, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.580427, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=3)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.304029, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.382263, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.221860, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.797145, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.833642, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.296650, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.123217, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.292744, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.536164, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.005458, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.047737, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 0.926840, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.867340, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.890617, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.968017, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 2.265842, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Loss: 0.684985, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.196859, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.603870, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.819279, Train accuracy: 1.000000, val accuracy: 0.133333\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=2e-1, num_epochs=20, batch_size=3)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.279923, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237889, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257575, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287211, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293256, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.307740, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275753, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245575, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.204830, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.216866, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.195558, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.218793, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.332608, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.201948, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.071311, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251302, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299578, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.207358, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257298, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273642, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.197121, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.145319, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.184244, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267823, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.136418, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.152879, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.252110, Train accuracy: 0.200556, val accuracy: 0.209000\n",
      "Loss: 2.207174, Train accuracy: 0.207222, val accuracy: 0.213000\n",
      "Loss: 2.256488, Train accuracy: 0.217556, val accuracy: 0.224000\n",
      "Loss: 2.169142, Train accuracy: 0.228333, val accuracy: 0.231000\n",
      "Loss: 2.024085, Train accuracy: 0.236667, val accuracy: 0.248000\n",
      "Loss: 2.099476, Train accuracy: 0.244556, val accuracy: 0.250000\n",
      "Loss: 2.128964, Train accuracy: 0.249889, val accuracy: 0.247000\n",
      "Loss: 2.102638, Train accuracy: 0.257111, val accuracy: 0.254000\n",
      "Loss: 2.156080, Train accuracy: 0.261444, val accuracy: 0.262000\n",
      "Loss: 1.955365, Train accuracy: 0.268556, val accuracy: 0.267000\n",
      "Loss: 2.069692, Train accuracy: 0.271778, val accuracy: 0.271000\n",
      "Loss: 1.936895, Train accuracy: 0.277111, val accuracy: 0.278000\n",
      "Loss: 2.082891, Train accuracy: 0.284333, val accuracy: 0.286000\n",
      "Loss: 1.987546, Train accuracy: 0.289667, val accuracy: 0.292000\n",
      "Loss: 2.152852, Train accuracy: 0.295333, val accuracy: 0.300000\n",
      "Loss: 1.854205, Train accuracy: 0.303000, val accuracy: 0.308000\n",
      "Loss: 1.968895, Train accuracy: 0.308889, val accuracy: 0.318000\n",
      "Loss: 1.946218, Train accuracy: 0.317333, val accuracy: 0.325000\n",
      "Loss: 1.810207, Train accuracy: 0.324222, val accuracy: 0.326000\n",
      "Loss: 1.982436, Train accuracy: 0.331778, val accuracy: 0.332000\n",
      "Loss: 2.004635, Train accuracy: 0.343222, val accuracy: 0.344000\n",
      "Loss: 1.829896, Train accuracy: 0.354444, val accuracy: 0.351000\n",
      "Loss: 1.879626, Train accuracy: 0.362889, val accuracy: 0.360000\n",
      "Loss: 1.652269, Train accuracy: 0.374444, val accuracy: 0.376000\n",
      "Loss: 1.756866, Train accuracy: 0.385778, val accuracy: 0.377000\n",
      "Loss: 1.695151, Train accuracy: 0.391556, val accuracy: 0.384000\n",
      "Loss: 1.649250, Train accuracy: 0.403444, val accuracy: 0.389000\n",
      "Loss: 1.771052, Train accuracy: 0.413889, val accuracy: 0.400000\n",
      "Loss: 1.956576, Train accuracy: 0.419889, val accuracy: 0.411000\n",
      "Loss: 1.534421, Train accuracy: 0.430222, val accuracy: 0.421000\n",
      "Loss: 1.671424, Train accuracy: 0.437778, val accuracy: 0.433000\n",
      "Loss: 1.636075, Train accuracy: 0.444444, val accuracy: 0.439000\n",
      "Loss: 1.618842, Train accuracy: 0.453000, val accuracy: 0.439000\n",
      "Loss: 1.453775, Train accuracy: 0.459889, val accuracy: 0.455000\n",
      "Loss: 1.369287, Train accuracy: 0.467222, val accuracy: 0.460000\n",
      "Loss: 1.533228, Train accuracy: 0.477667, val accuracy: 0.478000\n",
      "Loss: 1.562624, Train accuracy: 0.485222, val accuracy: 0.476000\n",
      "Loss: 1.738768, Train accuracy: 0.488111, val accuracy: 0.490000\n",
      "Loss: 1.700787, Train accuracy: 0.500778, val accuracy: 0.495000\n",
      "Loss: 1.621379, Train accuracy: 0.506889, val accuracy: 0.499000\n",
      "Loss: 1.431140, Train accuracy: 0.516222, val accuracy: 0.515000\n",
      "Loss: 1.453731, Train accuracy: 0.519000, val accuracy: 0.513000\n",
      "Loss: 1.471660, Train accuracy: 0.527444, val accuracy: 0.524000\n",
      "Loss: 1.533912, Train accuracy: 0.533111, val accuracy: 0.527000\n",
      "Loss: 1.532234, Train accuracy: 0.541000, val accuracy: 0.535000\n",
      "Loss: 1.252723, Train accuracy: 0.549111, val accuracy: 0.541000\n",
      "Loss: 1.380826, Train accuracy: 0.550444, val accuracy: 0.550000\n",
      "Loss: 1.409618, Train accuracy: 0.556889, val accuracy: 0.558000\n",
      "Loss: 1.152790, Train accuracy: 0.564333, val accuracy: 0.565000\n",
      "Loss: 1.392050, Train accuracy: 0.571333, val accuracy: 0.566000\n",
      "Loss: 1.491795, Train accuracy: 0.575556, val accuracy: 0.567000\n",
      "Loss: 1.269115, Train accuracy: 0.579111, val accuracy: 0.568000\n",
      "Loss: 1.795290, Train accuracy: 0.583778, val accuracy: 0.572000\n",
      "Loss: 1.305446, Train accuracy: 0.590889, val accuracy: 0.579000\n",
      "Loss: 1.493918, Train accuracy: 0.595111, val accuracy: 0.585000\n",
      "Loss: 1.450452, Train accuracy: 0.600556, val accuracy: 0.582000\n",
      "Loss: 1.523213, Train accuracy: 0.601556, val accuracy: 0.588000\n",
      "Loss: 1.361186, Train accuracy: 0.607889, val accuracy: 0.598000\n",
      "Loss: 1.472070, Train accuracy: 0.612667, val accuracy: 0.601000\n",
      "Loss: 1.497603, Train accuracy: 0.615667, val accuracy: 0.592000\n",
      "Loss: 1.282850, Train accuracy: 0.621222, val accuracy: 0.599000\n",
      "Loss: 1.441691, Train accuracy: 0.625111, val accuracy: 0.603000\n",
      "Loss: 1.123158, Train accuracy: 0.626667, val accuracy: 0.609000\n",
      "Loss: 1.187082, Train accuracy: 0.630000, val accuracy: 0.612000\n",
      "Loss: 1.015523, Train accuracy: 0.633333, val accuracy: 0.615000\n",
      "Loss: 1.095146, Train accuracy: 0.635889, val accuracy: 0.618000\n",
      "Loss: 1.219159, Train accuracy: 0.639111, val accuracy: 0.616000\n",
      "Loss: 1.557610, Train accuracy: 0.643222, val accuracy: 0.624000\n",
      "Loss: 1.078632, Train accuracy: 0.645556, val accuracy: 0.629000\n",
      "Loss: 1.075698, Train accuracy: 0.651333, val accuracy: 0.629000\n",
      "Loss: 1.222750, Train accuracy: 0.653667, val accuracy: 0.631000\n",
      "Loss: 1.226451, Train accuracy: 0.657667, val accuracy: 0.637000\n",
      "Loss: 1.213792, Train accuracy: 0.660778, val accuracy: 0.645000\n",
      "Loss: 1.003072, Train accuracy: 0.662000, val accuracy: 0.644000\n",
      "Loss: 1.127230, Train accuracy: 0.666111, val accuracy: 0.649000\n",
      "Loss: 0.906665, Train accuracy: 0.668111, val accuracy: 0.648000\n",
      "Loss: 0.979775, Train accuracy: 0.670111, val accuracy: 0.652000\n",
      "Loss: 1.173703, Train accuracy: 0.674667, val accuracy: 0.649000\n",
      "Loss: 1.162633, Train accuracy: 0.674444, val accuracy: 0.651000\n",
      "Loss: 0.947422, Train accuracy: 0.677667, val accuracy: 0.653000\n",
      "Loss: 0.994709, Train accuracy: 0.682000, val accuracy: 0.664000\n",
      "Loss: 1.304772, Train accuracy: 0.681889, val accuracy: 0.661000\n",
      "Loss: 0.841146, Train accuracy: 0.683222, val accuracy: 0.664000\n",
      "Loss: 1.052827, Train accuracy: 0.686778, val accuracy: 0.663000\n",
      "Loss: 1.163567, Train accuracy: 0.689222, val accuracy: 0.668000\n",
      "Loss: 0.916163, Train accuracy: 0.691778, val accuracy: 0.672000\n",
      "Loss: 1.337020, Train accuracy: 0.693333, val accuracy: 0.674000\n",
      "Loss: 1.492963, Train accuracy: 0.696111, val accuracy: 0.675000\n",
      "Loss: 1.138975, Train accuracy: 0.697667, val accuracy: 0.673000\n",
      "Loss: 1.293375, Train accuracy: 0.699556, val accuracy: 0.675000\n",
      "Loss: 0.987883, Train accuracy: 0.701778, val accuracy: 0.675000\n",
      "Loss: 1.109757, Train accuracy: 0.704889, val accuracy: 0.678000\n",
      "Loss: 0.972302, Train accuracy: 0.708333, val accuracy: 0.682000\n",
      "Loss: 0.717249, Train accuracy: 0.709889, val accuracy: 0.685000\n",
      "Loss: 0.864279, Train accuracy: 0.707444, val accuracy: 0.687000\n",
      "Loss: 1.053875, Train accuracy: 0.709889, val accuracy: 0.692000\n",
      "Loss: 1.052244, Train accuracy: 0.711778, val accuracy: 0.694000\n",
      "Loss: 1.045995, Train accuracy: 0.713333, val accuracy: 0.691000\n",
      "Loss: 0.643076, Train accuracy: 0.714778, val accuracy: 0.700000\n",
      "Loss: 1.239913, Train accuracy: 0.713667, val accuracy: 0.695000\n",
      "Loss: 1.290313, Train accuracy: 0.713444, val accuracy: 0.695000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.060434, Train accuracy: 0.719222, val accuracy: 0.695000\n",
      "Loss: 1.086367, Train accuracy: 0.718222, val accuracy: 0.696000\n",
      "Loss: 1.183382, Train accuracy: 0.723000, val accuracy: 0.699000\n",
      "Loss: 1.211539, Train accuracy: 0.723556, val accuracy: 0.698000\n",
      "Loss: 1.027992, Train accuracy: 0.722556, val accuracy: 0.697000\n",
      "Loss: 0.973413, Train accuracy: 0.723667, val accuracy: 0.702000\n",
      "Loss: 0.704426, Train accuracy: 0.727333, val accuracy: 0.698000\n",
      "Loss: 0.846684, Train accuracy: 0.725667, val accuracy: 0.700000\n",
      "Loss: 0.666993, Train accuracy: 0.728667, val accuracy: 0.698000\n",
      "Loss: 1.034087, Train accuracy: 0.728889, val accuracy: 0.697000\n",
      "Loss: 1.124146, Train accuracy: 0.730000, val accuracy: 0.699000\n",
      "Loss: 0.811061, Train accuracy: 0.734000, val accuracy: 0.702000\n",
      "Loss: 0.807566, Train accuracy: 0.732111, val accuracy: 0.702000\n",
      "Loss: 1.044415, Train accuracy: 0.733667, val accuracy: 0.704000\n",
      "Loss: 0.839867, Train accuracy: 0.734667, val accuracy: 0.704000\n",
      "Loss: 0.780199, Train accuracy: 0.739333, val accuracy: 0.702000\n",
      "Loss: 0.861923, Train accuracy: 0.737778, val accuracy: 0.712000\n",
      "Loss: 0.851696, Train accuracy: 0.739111, val accuracy: 0.710000\n",
      "Loss: 1.062897, Train accuracy: 0.740444, val accuracy: 0.711000\n",
      "Loss: 0.875684, Train accuracy: 0.740111, val accuracy: 0.703000\n",
      "Loss: 0.776283, Train accuracy: 0.741222, val accuracy: 0.708000\n",
      "Loss: 0.865711, Train accuracy: 0.742444, val accuracy: 0.710000\n",
      "Loss: 0.873411, Train accuracy: 0.744556, val accuracy: 0.707000\n",
      "Loss: 0.864369, Train accuracy: 0.746000, val accuracy: 0.711000\n",
      "Loss: 0.765341, Train accuracy: 0.746667, val accuracy: 0.710000\n",
      "Loss: 0.824261, Train accuracy: 0.748333, val accuracy: 0.712000\n",
      "Loss: 0.954489, Train accuracy: 0.750556, val accuracy: 0.712000\n",
      "Loss: 0.903490, Train accuracy: 0.749333, val accuracy: 0.716000\n",
      "Loss: 0.681472, Train accuracy: 0.751556, val accuracy: 0.709000\n",
      "Loss: 0.856033, Train accuracy: 0.753444, val accuracy: 0.716000\n",
      "Loss: 0.822191, Train accuracy: 0.754778, val accuracy: 0.712000\n",
      "Loss: 0.735895, Train accuracy: 0.756222, val accuracy: 0.714000\n",
      "Loss: 1.167081, Train accuracy: 0.754667, val accuracy: 0.713000\n",
      "Loss: 0.826010, Train accuracy: 0.756111, val accuracy: 0.715000\n",
      "Loss: 0.770436, Train accuracy: 0.757000, val accuracy: 0.715000\n",
      "Loss: 0.788831, Train accuracy: 0.761222, val accuracy: 0.719000\n",
      "Loss: 0.998495, Train accuracy: 0.763111, val accuracy: 0.718000\n",
      "Loss: 0.867971, Train accuracy: 0.762444, val accuracy: 0.718000\n",
      "Loss: 1.041475, Train accuracy: 0.762667, val accuracy: 0.721000\n",
      "Loss: 0.496349, Train accuracy: 0.764333, val accuracy: 0.720000\n",
      "Loss: 0.723107, Train accuracy: 0.766222, val accuracy: 0.716000\n",
      "Loss: 0.613639, Train accuracy: 0.765000, val accuracy: 0.715000\n",
      "Loss: 0.833468, Train accuracy: 0.767667, val accuracy: 0.717000\n",
      "Loss: 0.883014, Train accuracy: 0.769333, val accuracy: 0.720000\n",
      "Loss: 1.267066, Train accuracy: 0.769889, val accuracy: 0.719000\n",
      "Loss: 0.586185, Train accuracy: 0.770556, val accuracy: 0.722000\n",
      "Loss: 1.005978, Train accuracy: 0.772889, val accuracy: 0.723000\n",
      "Loss: 0.923847, Train accuracy: 0.771889, val accuracy: 0.720000\n",
      "Loss: 0.834621, Train accuracy: 0.773111, val accuracy: 0.721000\n",
      "Loss: 0.719367, Train accuracy: 0.774667, val accuracy: 0.724000\n",
      "Loss: 0.715759, Train accuracy: 0.775000, val accuracy: 0.722000\n",
      "Loss: 0.889125, Train accuracy: 0.776889, val accuracy: 0.723000\n",
      "Loss: 0.885190, Train accuracy: 0.775111, val accuracy: 0.725000\n",
      "Loss: 0.575334, Train accuracy: 0.778000, val accuracy: 0.719000\n",
      "Loss: 0.982479, Train accuracy: 0.778111, val accuracy: 0.722000\n",
      "Loss: 0.734621, Train accuracy: 0.779222, val accuracy: 0.723000\n",
      "Loss: 0.621587, Train accuracy: 0.782222, val accuracy: 0.722000\n",
      "Loss: 0.621874, Train accuracy: 0.781889, val accuracy: 0.721000\n",
      "Loss: 0.845372, Train accuracy: 0.780778, val accuracy: 0.720000\n",
      "Loss: 0.854306, Train accuracy: 0.785667, val accuracy: 0.723000\n",
      "Loss: 0.987130, Train accuracy: 0.785000, val accuracy: 0.726000\n",
      "Loss: 0.944798, Train accuracy: 0.785444, val accuracy: 0.733000\n",
      "Loss: 0.766350, Train accuracy: 0.785333, val accuracy: 0.728000\n",
      "Loss: 0.776290, Train accuracy: 0.787667, val accuracy: 0.731000\n",
      "Loss: 0.844905, Train accuracy: 0.786333, val accuracy: 0.728000\n",
      "Loss: 0.678757, Train accuracy: 0.788333, val accuracy: 0.728000\n",
      "Loss: 0.519710, Train accuracy: 0.790556, val accuracy: 0.732000\n",
      "Loss: 0.558873, Train accuracy: 0.791444, val accuracy: 0.728000\n",
      "Loss: 0.900704, Train accuracy: 0.790000, val accuracy: 0.732000\n",
      "Loss: 0.714819, Train accuracy: 0.792556, val accuracy: 0.731000\n",
      "Loss: 0.458085, Train accuracy: 0.793222, val accuracy: 0.732000\n",
      "Loss: 0.904305, Train accuracy: 0.793667, val accuracy: 0.737000\n",
      "Loss: 0.692129, Train accuracy: 0.792778, val accuracy: 0.733000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-2\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output=10, hidden_layer_size=hidden_layer_size, \n",
    "                    reg=reg_strength)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=learning_rates, num_epochs=num_epochs, \n",
    "                  batch_size=batch_size, learning_rate_decay=learning_rate_decay)\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff7fa409e80>]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.694000\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
